\chapter{Zusammenfassung und Ausblick}\label{ch:conclusion}

\section{Zusammenfassung}\label{sec:summary}

Vor dem Hintergrund des demografischen Wandels und steigender Antragszahlen ist die Automatisierung von Verwaltungsprozessen für die Bundesagentur für Arbeit von Bedeutung.
Die vorliegende Bachelorarbeit untersuchte das Potenzial von multimodalen Large Language Models als Nachfolger für die bestehende OCR/YOLO-Pipeline zur Verarbeitung von Ausbildungsnachweisen volljähriger Auszubildender.
Ziel war es, die Extraktionsleistung der bisherigen Lösung unter Beobachtung des Ressourcenverbrauchs zu verbessern.

Im Rahmen der Evaluation wurden die Modelle Pixtral-12B, Qwen-2.5-VL-7B und Qwen-2.5-VL-32B gegen die Pipeline getestet.
Ein zentraler Bestandteil der Untersuchung war das Fine-Tuning des kleineren 7B-Modells mittels LoRA, um dessen Leistungsfähigkeit gegenüber dem Qwen-2.5-VL-32B zu bewerten.

Die Ergebnisse zeigen, dass die herkömmliche OCR/YOLO-Pipeline bei heterogenen Ausbildungsverträgen an ihre Grenzen stößt.
Die VLMs konnten hier eine Leistungssteigerung erzielen.
Das Qwen-2.5-VL-32B lieferte die besten Ergebnisse, erwies sich jedoch aufgrund einer durchschnittlichen \gls{Latenz} von 64 Sekunden und eines extrem hohen Energiebedarfs als unwirtschaftlich.
Das nachtrainierte Qwen-2.5-VL-7B-finetuned bestätigte, dass domänenspezifisch angepasste kleine Modelle mit großen Generalisten konkurrieren können.
Zwar steigt der Energieverbrauch im Vergleich zur alten Pipeline an, dem steht jedoch die Minderung der manuellen Nachbearbeitung gegenüber.

Als Fazit ergibt sich, dass der Einsatz eines kleinen, angepassten Modells den nächsten logischen Schritt in der teilautomatisierten Verarbeitung von Dokumenten darstellt.

\section{Ausblick}\label{sec:outlook}

Obwohl der entwickelte Prototyp bereits vielversprechende Ergebnisse liefert, stehen dem Einsatz in einer produktiven Umgebung noch Hürden im Weg.
Die Umgebung der bisherigen Pipeline muss für den Einsatz angepasst und die Ausgabe des VLMs stabilisiert werden.
Durch die Einführung von Constrained Decoding mithilfe von \gls{vLLM} wird in Zukunft die Generierung der \gls{JSON}-Objekte sichergestellt.
Außerdem ermöglicht das Auslesen von Token-Wahrscheinlichkeiten eine Auswertung der Konfidenz für die Klassifikation.

Hinsichtlich der Robustheit muss die VLM-Pipeline für komplexere Szenarien, wie zum Beispiel vermischte oder lange Dokumente, weiter angepasst werden.

Um das Potenzial trainierter Modelle anderen Fachverfahren zu erläutern, wird der Proof of Concept in den jeweiligen Abteilungen vorgestellt.
Dies fördert die weitere Digitalisierung der Bundesagentur für Arbeit.