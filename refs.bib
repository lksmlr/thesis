@misc{KG5b,
    author = {Bundesagentur f체r Arbeit},
    title = {Erkl채rung zum Ausbildungsverh채ltnis (KG 5b)},
    year = {2022},
    howpublished = {\url{https://www.arbeitsagentur.de/datei/dok_ba031910.pdf}}
}

@misc{Vertrag,
    author = {Deutsche Industrie- und Handelskammer},
    title = {Berufsausbildungsvertrag},
    year = {2025},
    howpublished = {\url{https://www.dihk.de/resource/blob/140492/9f4fa2617d668aa62f5d3caad77cdbaa/bildung-musterausbildungsvertrag-data.pdf}},
}

@misc{AnzahlAntraegeProJahr,
    author = {Bundesagentur f체r Arbeit},
    title = {Kindergeld / Kinderzuschlag Jahreszahlen 2024},
    year = {2024},
    howpublished = {\url{https://statistik.arbeitsagentur.de/Statistikdaten/Detail/202412/famka/famka-jz/famka-jz-d-0-202412-pdf.pdf?__blob=publicationFile&v=3}},
}

@misc{NVIDIAA40,
    author = {NVIDIA},
    title = {NVIDIA A40},
    year = {2022},
    howpublished = {\url{https://www.nvidia.com/de-de/data-center/a40/}},
}

@misc{Pixtral12B,
    author = {Pixtral},
    title = {Pixtral-12B-2409},
    year = {2024},
    howpublished = {\url{https://huggingface.co/mistralai/Pixtral-12B-2409}},
}

@article{PixtralPaper,
    title         = {Pixtral 12B},
    author        = {Agrawal, Pravesh and others},
    year          = {2024},
    eprint        = {2410.07073},
    archivePrefix = {arXiv},
    primaryClass  = {cs.CV},
    url           = {https://arxiv.org/abs/2410.07073}
}

@misc{Qwen7B,
    author = {Qwen},
    title = {Qwen2.5VL-7B-instruct},
    year = {2025},
    howpublished = {\url{https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct}},
}

@misc{Qwen32B,
    author = {Qwen},
    title = {Qwen2.5VL-32B-instruct},
    year = {2025},
    howpublished = {\url{https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct}},
}

@article{QwenPaper,
    title         = {Qwen2.5-VL Technical Report},
    author        = {Bai, Shuai and others},
    year          = {2024},
    eprint        = {2502.13923},
    archivePrefix = {arXiv},
    primaryClass  = {cs.CV},
    url           = {https://arxiv.org/abs/2502.13923}
}

@article{DocVQA,
    title         = {DocVQA: A Dataset for VQA on Document Images},
    author        = {Minesh, Mathew and Dimosthenis, Karatzas and C.V., Jawahar},
    year          = {2021},
    eprint        = {2007.00398},
    archivePrefix = {arXiv},
    primaryClass  = {cs.CV},
    url           = {https://arxiv.org/abs/2007.00398}
}

@book{IE,
    title={Speech and Language Processing},
    author={Jurafsky, Daniel and Martin, James H.},
    year={2026},
    publisher={Stanford University},
    note={Draft of Chapter 18: Information Extraction},
    url={https://web.stanford.edu/~jurafsky/slp3/}
}

@article{gld,
    author={Yujian, Li and Bo, Liu},
    journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
    title={A Normalized Levenshtein Distance Metric},
    year={2007},
    doi={10.1109/TPAMI.2007.1078}
}

@article{prompt_engineering,
    title         = {Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing},
    author        = {Liu, Pengfei and others},
    year          = {2021},
    eprint        = {2107.13586},
    archivePrefix = {arXiv},
    primaryClass  = {cs.CV},
    url           = {https://arxiv.org/abs/2107.13586}
}

@article{few_shot_learners,
    title         = {Language Models are Few-Shot Learners},
    author        = {Brown, Tom B. and others},
    year          = {2020},
    eprint        = {2005.14165},
    archivePrefix = {arXiv},
    primaryClass  = {cs.CV},
    url           = {https://arxiv.org/abs/2005.14165}
}

@article{LoRA,
    title         = {LoRA: Low-Rank Adaptation of Large Language Models},
    author        = {Hu, Edward J. and others},
    year          = {2021},
    eprint        = {2106.09685},
    archivePrefix = {arXiv},
    primaryClass  = {cs.CV},
    url           = {https://arxiv.org/abs/2106.09685}
}

@Misc{peft,
    title =        {PEFT: State-of-the-art Parameter-Efficient Fine-Tuning methods},
    author =       {Mangrulkar, Sourab and others},
    howpublished = {\url{https://github.com/huggingface/peft}},
    year =         {2022}
}

@article{rsLoRA,
    title         = {A Rank Stabilization Scaling Factor for Fine-Tuning with LoRA},
    author        = {Kalajdzievski, Damjan},
    year          = {2023},
    eprint        = {2312.03732},
    archivePrefix = {arXiv},
    primaryClass  = {cs.CV},
    url           = {https://arxiv.org/abs/2312.03732}
}

@article{DocumentAI,
    title         = {Document AI: Benchmarks, Models and Applications},
    author        = {Cui, Lei and others},
    year          = {2021},
    eprint        = {2111.08609},
    archivePrefix = {arXiv},
    primaryClass  = {cs.CV},
    url           = {https://arxiv.org/abs/2111.08609}
}

@article{chargrid,
    title         = {Chargrid: Towards Understanding 2D Documents},
    author        = {Katti, Anoop R. and others},
    year          = {2018},
    eprint        = {1809.08799},
    archivePrefix = {arXiv},
    primaryClass  = {cs.CV},
    url           = {https://arxiv.org/abs/1809.08799}
}

@article{LayoutLM,
    title         = {LayoutLM: Pre-training of Text and Layout for Document Image Understanding},
    author        = {Xu, Yiheng and others},
    year          = {2020},
    eprint        = {1912.13318v5},
    archivePrefix = {arXiv},
    primaryClass  = {cs.CV},
    url           = {https://arxiv.org/abs/1912.13318v5}
}

@article{Donut,
    title         = {OCR-free Document Understanding Transformer},
    author        = {Kim, Geewook and others},
    year          = {2022},
    eprint        = {2111.15664},
    archivePrefix = {arXiv},
    primaryClass  = {cs.CV},
    url           = {https://arxiv.org/abs/2111.15664}
}

