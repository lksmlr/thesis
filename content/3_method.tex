\chapter{Methodik und Datenaufbereitung}\label{ch:data}

%TODO:Forschungsfragen

\section{Modellierung der Dokumentenarten als JSON}\label{sec:documents_as_json}

Um eine standardisierte Weiterverarbeitung der Modellausgaben zu gewährleisten, ist eine feste Struktur essenziell.
Da moderne \glspl{VLM} darauf trainiert sind, Antworten im \gls{JSON}-Format zu liefern, werden die extrahierten Informationen in ein vordefiniertes \gls{JSON}-Schema überführt.
Diese Schemata unterscheiden sich je nach Dokumentenart, da jeweils unterschiedliche Informationen relevant sind.


\subsection{KG5b}\label{subsec:json_kg5b}

Das Schema für das Formular KG5b ist in Abbildung~\ref{fig:json_kg5b} definiert.
Die Klassifikation spiegelt sich im Feld \texttt{type} wider, während die restlichen Felder Platzhalter für die \gls{IE} darstellen.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.5\textwidth]{figures/kg5b_json}
    \caption{JSON-Schema des Dokumententyps KG5b}
    \label{fig:json_kg5b}
\end{figure}


\subsection{Ausbildungsvertrag}\label{subsec:json_vertrag}

Das Schema für die Ausbildungsverträge ist in Abbildung~\ref{fig:json_vertrag} definiert.
Wie im Schema des KG5b dient das Feld \texttt{type} der Klassifikation, während die restlichen Felder die \gls{IE} repräsentieren.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.5\textwidth]{figures/vertrag_json}
    \caption{JSON-Schema des Dokumententyps Ausbildungsvertrag}
    \label{fig:json_vertrag}
\end{figure}


\subsection{Sonstige Dokumente}\label{subsec:json_sonstiges}

Das Schema für die nicht relevanten Dokumente ist in Abbildung~\ref{fig:json_sonstiges} definiert.
Da hier keine Informationen benötigt werden, sondern rein die Klassifikation von Nutzen ist, besteht das Schema ausschließlich aus dem Feld \texttt{type}.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.5\textwidth]{figures/sonstiges_json}
    \caption{JSON-Schema des Dokumententyps Sonstiges}
    \label{fig:json_sonstiges}
\end{figure}


\section{Evaluation}\label{sec:evaluation}
%TODO: Wie sicherstellen JSON output

Um die generierte \gls{JSON} des \glspl{VLM} schlussendlich bewerten zu können, werden verschiedene Vorverarbeitungschritte

\subsection{Vergleichslogik der unterschiedlichen JSON-Felder}\label{subsec:comparator}

Um ein realistisches Ergebnis zu erhalten, müssen unterschiedliche Feldtypen spezifisch verglichen werden.
Die Menge an distinkten Typen beinhaltet: Namen, Booleans, Zeichenketten, Daten und Monate.

Namen werden mit der Levenshtein-Similarity verglichen, um kleinere Fehler oder verschiedene Varianten zu tolerieren.
Beispielsweise wird ein Name, der \texttt{ue} statt \texttt{ü} enthält, nicht als Fehler erkannt.
Des Weiteren werden minimale \gls{OCR}-Fehler gefiltert.
Die \gls{YOLO}/\gls{OCR}-Pipeline verwendet ebenso diesen Vergleich mit den gleichen Schwellenwerten, somit wird das Ergebnis vergleichbar.

Zeichenketten und Booleans werden exakt verglichen.
Hierzu zählen die Felder \texttt{type}, \texttt{stamp\_company}, \texttt{signature\_company}, \texttt{signature\_child}, \texttt{signature\_legal\_guardian} und \texttt{apprenticeship\_finished}.
Lediglich die booleschen Werte werden zu \texttt{true} normalisiert, da hier eine potenzielle Fehlerquelle liegt.

Daten werden einheitlich in das Format DD.MM.YYYY gebracht, obwohl dies nicht dem internationalen Standard entspricht.
Das ist darauf zurückzuführen, dass so die Erkennung des \glspl{VLM} am robustesten ist, da die deutschen Dokumente auch mit diesem Format ausgefüllt werden.

Monate werden in das Format MM normalisiert.
Hierbei werden ausgeschriebene Monatsnamen sowie vollständige Datumsangaben angepasst.

\subsection{Bewertung der Klassifikation}\label{subsec:evaluation_classification}

Die Bewertung der Klassifikation ist ein Multiclass-Problem, da hier mehr als zwei Klassen vorliegen (KG5b, Ausbildungsvertrag, Sonstiges).
Um die Güte der Modelle zu betrachten, wird eine Confusion-Matrix herangezogen sowie die Accuracy gemessen.
Durch die gleichverteilung der Klassen in den Datensätzen werden hier keine weiteren Metriken gebraucht.

\subsection{Bewertung der Information Extraction}\label{subsec:evaluation_ie}

Um den Entity-Level F1-Score, der die Hauptmetrik für den Vergleich darstellt, zu berechnen werden einige Metadaten für jede generierte \gls{JSON} bestimmt.
Dazu gehören die Status der Felder, also ob diese vorhanden, nicht vorhanden oder halluziniert sind.
Sobald ein Feld als vorhanden markiert wird, wird mit den verschiedenen Vergleichslogiken die Richtigkeit der Felder bestimmt und den Metadaten hinzugefügt.

Auf Basis dieser Metadaten werden für den gesamten Dokumentenkorpus die True Positive (\gls{TP}), False Positive (\gls{FP}) und False Negative (\gls{FN}) gezählt.
Ein Feld zählt als \gls{TP}, wenn es vorhanden sowie korrekt ist.
Zu den \gls{FN} gehören Felder, die entweder fehlen oder vorhanden aber falsch sind.
Ein Feld, das vorhanden aber falsch ist, zählt zusätzlich zu den \gls{FP} zusammen mit den Feldern die halluziniert wurden.
Diese doppelte Bestrafung stellt eine sehr strenge Bewertung für inhaltliche Fehler dar.
\glspl{TN} sind in dem Falle nicht zählbar, da die Menge an nicht gefundenen Feldern, in denen nichts stande, unendlich groß ist.


\section{Daten}\label{sec:data}

\subsection{Datenvorbereitung}\label{subsec:preprocessing}

Durch Datenlieferungen der Familienkasse stehen mehrere Tausend Dokumente als PDF oder Bilddatei bereit.
Um eine einheitliche Basis zu schaffen und gute Ergebnisse zu erzielen, müssen die Daten vorbereitet werden.
Speziell die Drehung der Bilddateien sowie die Konvertierung der PDFs in Bilddateien stehen im Vordergrund.

Um die Drehung der Bilddateien zu korrigieren, werden die Exchangeable Image File Format (\gls{EXIF})-Daten ausgelesen.
Mithilfe dieser wird die originale Ausrichtung wieder hergestellt.

Bei älteren \glspl{VLM} wurden Bilder naiv auf eine bestimmte Größe skaliert.
Die hier verwendeten Modelle unterstützen eine dynamische Skalierung.
Um dennoch die maximale Tokenanzahl der Bilder zu begrenzen, werden diese vor der Weitergabe an das \gls{VLM} auf eine maximale Pixelanzahl skaliert.
Dabei wird jedoch das Seitenverhältnis beibehalten, um möglichst viele Details beizubehalten.

\subsection{Testdatensatz}\label{subsec:test_dataset}

\subsection{Trainingsdatensatz}\label{subsec:train_dataset}

\section{Modellauswahl}\label{sec:modelselection}
- Promptdesign
- warum kein one shot few shot usw
\section{Fine-Tuning}\label{sec:fine_tuning}
